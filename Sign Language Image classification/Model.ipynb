{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1553a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #GPU 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5930e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 튜닝\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE':128, #이미지 사이즈\n",
    "    'EPOCHS':50, #에포크\n",
    "    'LEARNING_RATE':2e-2, #학습률\n",
    "    'BATCH_SIZE':12, #배치사이즈\n",
    "    'SEED':41, #시드\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75391f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed 고정\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f904fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = 'G:/내 드라이브/DACON/Sign Language Image classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61713fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>10-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>10-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name label\n",
       "0   001.png  10-2\n",
       "1   002.png  10-1\n",
       "2   003.png     3\n",
       "3   004.png     8\n",
       "4   005.png     9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label_df = pd.read_csv(current_path + 'data/user_data/train.csv')\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcccc8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858 entries, 0 to 857\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  858 non-null    object\n",
      " 1   label      858 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "label_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27937ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['label'][label_df['label'] == '10-1'] = 10 ## label : 10-1 -> 10\n",
    "label_df['label'][label_df['label'] == '10-2'] = 0 ## Label : 10-2 -> 0\n",
    "label_df['label'] = label_df['label'].apply(lambda x : int(x)) ## Dtype : object -> int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ffe5471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  label\n",
       "0   001.png      0\n",
       "1   002.png     10\n",
       "2   003.png      3\n",
       "3   004.png      8\n",
       "4   005.png      9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "339bb9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858 entries, 0 to 857\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  858 non-null    object\n",
      " 1   label      858 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "label_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffc5a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def get_train_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # get image path\n",
    "    img_path_list.extend(data_dir + '*.png')\n",
    "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "        \n",
    "    # get label\n",
    "    #label_df = pd.read_csv(data_dir+'/train.csv')\n",
    "    label_list.extend(label_df['label'])\n",
    "                \n",
    "    return img_path_list, label_list\n",
    "\n",
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    \n",
    "    # get image path\n",
    "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
    "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "    \n",
    "    return img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72339110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:/내 드라이브/DACON/Sign Language Image classification/data/user_data/train'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path + 'data/user_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4bec582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:/내 드라이브/DACON/Sign Language Image classification/data/user_data/train/']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(current_path + 'data/user_data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb118324",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11588/2014620145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_img_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'data/user_data/train/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_img_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'data/user_data/test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11588/816424708.py\u001b[0m in \u001b[0;36mget_train_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# get image path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg_path_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimg_path_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# get label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11588/816424708.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# get image path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg_path_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimg_path_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# get label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'G'"
     ]
    }
   ],
   "source": [
    "all_img_path, all_label = get_train_data(current_path + 'data/user_data/train/')\n",
    "test_img_path = get_test_data(current_path + 'data/user_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a226a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets # 이미지 데이터셋 집합체\n",
    "import torchvision.transforms as transforms # 이미지 변환 툴\n",
    "\n",
    "from torch.utils.data import DataLoader # 학습 및 배치로 모델에 넣어주기 위한 툴\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None): #필요한 변수들을 선언\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index): #index번째 data를 return\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        image = cv2.imread(img_path)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self): #길이 return\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train : Validation = 0.8 : 0.25 Split\n",
    "train_len = int(len(all_img_path)*0.75)\n",
    "Vali_len = int(len(all_img_path)*0.25)\n",
    "\n",
    "train_img_path = all_img_path[:train_len]\n",
    "train_label = all_label[:train_len]\n",
    "\n",
    "vali_img_path = all_img_path[train_len:]\n",
    "vali_label = all_label[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bde3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train set 길이 : ', train_len)\n",
    "print('vaildation set 길이 : ', Vali_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                    transforms.ToPILImage(), #Numpy배열에서 PIL이미지로\n",
    "                    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]), #이미지 사이즈 변형\n",
    "                    transforms.ToTensor(), #이미지 데이터를 tensor\n",
    "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) #이미지 정규화\n",
    "                    \n",
    "                    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataloader\n",
    "\n",
    "#CustomDataset class를 통하여 train dataset생성\n",
    "train_dataset = CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform) \n",
    "#만든 train dataset를 DataLoader에 넣어 batch 만들기\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0) #BATCH_SIZE : 24\n",
    "\n",
    "#vaildation 에서도 적용\n",
    "vali_dataset = CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)\n",
    "vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = len(train_loader)\n",
    "vali_batches = len(vali_loader)\n",
    "\n",
    "print('total train imgs :',train_len,'/ total train batches :', train_batches)\n",
    "print('total valid imgs :',Vali_len, '/ total valid batches :', vali_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader)) #iter는 반복 가능한 객체에서 이터레이터를 반환하고, \n",
    "                                                        #next는 이터레이터에서 값을 차례대로 꺼냅니다. \n",
    "img = train_features[0]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img[0], cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a29837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Batch Labels shape: {train_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac081969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn # 신경망들이 포함됨\n",
    "#import torch.nn.init as init # 텐서에 초기값을 줌\n",
    "\n",
    "class CNNclassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNclassification, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1), #cnn layer\n",
    "            nn.ReLU(), #activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1), #cnn layer\n",
    "            nn.ReLU(), #activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), #cnn layer\n",
    "            nn.ReLU(), #activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
    "        \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=1), #cnn layer\n",
    "            nn.ReLU(), #activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
    "        \n",
    "        self.fc_layer = nn.Sequential( \n",
    "            nn.Linear(3136, 11) #fully connected layer(ouput layer)\n",
    "        )    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x) #1층\n",
    "        \n",
    "        x = self.layer2(x) #2층\n",
    "         \n",
    "        x = self.layer3(x) #3층\n",
    "        \n",
    "        x = self.layer4(x) #4층\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1) # N차원 배열 -> 1차원 배열\n",
    "        \n",
    "        out = self.fc_layer(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim # 최적화 알고리즘들이 포함힘\n",
    "\n",
    "model = CNNclassification().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff830ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, scheduler, device): \n",
    "    model.to(device)\n",
    "    n = len(train_loader)\n",
    "    \n",
    "    #Loss Function 정의\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1): #에포크 설정\n",
    "        model.train() #모델 학습\n",
    "        running_loss = 0.0\n",
    "            \n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            img, label = img.to(device), label.to(device) #배치 데이터\n",
    "            optimizer.zero_grad() #배치마다 optimizer 초기화\n",
    "        \n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img) #예측값 산출\n",
    "            loss = criterion(logit, label) #손실함수 계산\n",
    "            \n",
    "            # 역전파\n",
    "            loss.backward() #손실함수 기준 역전파 \n",
    "            optimizer.step() #가중치 최적화\n",
    "            running_loss += loss.item()\n",
    "              \n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        #Validation set 평가\n",
    "        model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
    "        vali_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for img, label in tqdm(iter(vali_loader)):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "\n",
    "                logit = model(img)\n",
    "                vali_loss += criterion(logit, label)\n",
    "                pred = logit.argmax(dim=1, keepdim=True)  #11개의 class중 가장 값이 높은 것을 예측 label로 추출\n",
    "                correct += pred.eq(label.view_as(pred)).sum().item() #예측값과 실제값이 맞으면 1 아니면 0으로 합산\n",
    "        vali_acc = 100 * correct / len(vali_loader.dataset)\n",
    "        print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.0f}%)\\n'.format(vali_loss / len(vali_loader), correct, len(vali_loader.dataset), 100 * correct / len(vali_loader.dataset)))\n",
    "        \n",
    "        #베스트 모델 저장\n",
    "        if best_acc < vali_acc:\n",
    "            best_acc = vali_acc\n",
    "            torch.save(model.state_dict(), '/Users/yujaehyeon/Desktop/DACON/Sign Language Image classification/best_model.pth') #이 디렉토리에 best_model.pth을 저장\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, train_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93471d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            img = img.to(device)\n",
    "\n",
    "            pred_logit = model(img)\n",
    "            pred_logit = pred_logit.argmax(dim=1, keepdim=True).squeeze(1)\n",
    "\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8afd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "# Validation Accuracy가 가장 뛰어난 모델을 불러옵니다.\n",
    "checkpoint = torch.load('/Users/yujaehyeon/Desktop/DACON/Sign Language Image classification/best_model.pth')\n",
    "model = CNNclassification().to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Inference\n",
    "preds = predict(model, test_loader, device)\n",
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/Users/yujaehyeon/Desktop/DACON/Sign Language Image classification/data/user_data/sample_submission.csv')\n",
    "submission['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label'][submission['label'] == 10] = '10-1' ## label : 10 -> '10-1'\n",
    "submission['label'][submission['label'] == 0] = '10-2' ## Label : 0 -> '10-2'\n",
    "submission['label'] = submission['label'].apply(lambda x : str(x)) ## Dtype : int -> object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3e78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
